{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import glob\n",
    "import random\n",
    "import pretty_midi\n",
    "import IPython\n",
    "import numpy as np\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "from random import shuffle, seed\n",
    "import numpy as np\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def piano_roll_to_pretty_midi(piano_roll, fs=100, program=0):\n",
    "    '''Convert a Piano Roll array into a PrettyMidi object\n",
    "     with a single instrument.\n",
    "    Parameters\n",
    "    ----------\n",
    "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
    "        Piano roll of one instrument\n",
    "    fs : int\n",
    "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    program : int\n",
    "        The program number of the instrument.\n",
    "    Returns\n",
    "    -------\n",
    "    midi_object : pretty_midi.PrettyMIDI\n",
    "        A pretty_midi.PrettyMIDI class instance describing\n",
    "        the piano roll.\n",
    "    '''\n",
    "    notes, frames = piano_roll.shape\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
    "\n",
    "    # use changes in velocities to find note on / note off events\n",
    "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track on velocities and note on times\n",
    "    prev_velocities = np.zeros(notes, dtype=int)\n",
    "    note_on_time = np.zeros(notes)\n",
    "\n",
    "    for time, note in zip(*velocity_changes):\n",
    "        # use time + 1 because of padding above\n",
    "        velocity = piano_roll[note, time + 1]\n",
    "        time = time / fs\n",
    "        if velocity > 0:\n",
    "            if prev_velocities[note] == 0:\n",
    "                note_on_time[note] = time\n",
    "                prev_velocities[note] = velocity\n",
    "        else:\n",
    "            pm_note = pretty_midi.Note(\n",
    "                velocity=prev_velocities[note],\n",
    "                pitch=note,\n",
    "                start=note_on_time[note],\n",
    "                end=time)\n",
    "            instrument.notes.append(pm_note)\n",
    "            prev_velocities[note] = 0\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_midi(folder = 'C:/Users/VISHESH/Desktop/cs/7th sem/AI/New folder/maestro-v1.0.0-midi/maestro-v1.0.0/*/*.midi', seed_int = 666):\n",
    "  \"\"\"Get the list of all midi file in the folders\n",
    "  \n",
    "  Parameters\n",
    "  ==========\n",
    "  folder : str\n",
    "    The midi folder.\n",
    "  seed_int : int\n",
    "    the random seed.\n",
    "  \n",
    "  Returns\n",
    "  =======\n",
    "  The midi files\n",
    "  \n",
    "  \"\"\"\n",
    "  list_all_midi = glob.glob(folder)\n",
    "  seed(seed_int)\n",
    "  shuffle(list_all_midi)\n",
    "  return list_all_midi\n",
    "\n",
    "list_all_midi = get_list_midi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoteTokenizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "      self.notes_to_index = {}\n",
    "      self.index_to_notes = {}\n",
    "      self.num_of_word = 0\n",
    "      self.unique_word = 0\n",
    "      self.notes_freq = {}\n",
    "        \n",
    "    def transform(self,list_array):\n",
    "      \"\"\" Transform a list of note in string into index.\n",
    "      \n",
    "      Parameters\n",
    "      ==========\n",
    "      list_array : list\n",
    "        list of note in string format\n",
    "      \n",
    "      Returns\n",
    "      =======\n",
    "      The transformed list in numpy array.\n",
    "      \n",
    "      \"\"\"\n",
    "      transformed_list = []\n",
    "      for instance in list_array:\n",
    "          transformed_list.append([self.notes_to_index[note] for note in instance])\n",
    "      return np.array(transformed_list, dtype=np.int32)\n",
    " \n",
    "    def partial_fit(self, notes):\n",
    "        \"\"\" Partial fit on the dictionary of the tokenizer\n",
    "        \n",
    "        Parameters\n",
    "        ==========\n",
    "        notes : list of notes\n",
    "        \n",
    "        \"\"\"\n",
    "        for note in notes:\n",
    "            note_str = ','.join(str(a) for a in note)\n",
    "            if note_str in self.notes_freq:\n",
    "                self.notes_freq[note_str] += 1\n",
    "                self.num_of_word += 1\n",
    "            else:\n",
    "                self.notes_freq[note_str] = 1\n",
    "                self.unique_word += 1\n",
    "                self.num_of_word += 1\n",
    "                self.notes_to_index[note_str], self.index_to_notes[self.unique_word] = self.unique_word, note_str\n",
    "            \n",
    "    def add_new_note(self, note):\n",
    "        \"\"\" Add a new note into the dictionary\n",
    "\n",
    "        Parameters\n",
    "        ==========\n",
    "        note : str\n",
    "          a new note who is not in dictionary.  \n",
    "\n",
    "        \"\"\"\n",
    "        assert note not in self.notes_to_index\n",
    "        self.unique_word += 1\n",
    "        self.notes_to_index[note], self.index_to_notes[self.unique_word] = self.unique_word, note\n",
    "        \n",
    "def generate_batch_song(list_all_midi, batch_music=16, start_index=0, fs=30, seq_len=50, use_tqdm=False):\n",
    "    \"\"\"\n",
    "    Generate Batch music that will be used to be input and output of the neural network\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    list_all_midi : list\n",
    "      List of midi files\n",
    "    batch_music : int\n",
    "      A number of music in one batch\n",
    "    start_index : int\n",
    "      The start index to be batched in list_all_midi\n",
    "    fs : int\n",
    "      Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    seq_len : int\n",
    "      The sequence length of the music to be input of neural network\n",
    "    use_tqdm : bool\n",
    "      Whether to use tqdm or not in the function\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    Tuple of input and target neural network\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(list_all_midi) >= batch_music\n",
    "    dict_time_notes = generate_dict_time_notes(list_all_midi, batch_music, start_index, fs, use_tqdm=use_tqdm)\n",
    "    \n",
    "    list_musics = process_notes_in_song(dict_time_notes, seq_len)\n",
    "    collected_list_input, collected_list_target = [], []\n",
    "     \n",
    "    for music in list_musics:\n",
    "        list_training, list_target = generate_input_and_target(music, seq_len)\n",
    "        collected_list_input += list_training\n",
    "        collected_list_target += list_target\n",
    "    return collected_list_input, collected_list_target\n",
    "\n",
    "def generate_dict_time_notes(list_all_midi, batch_song = 16, start_index=0, fs=30, use_tqdm=True):\n",
    "    \"\"\" Generate map (dictionary) of music ( in index ) to piano_roll (in np.array)\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    list_all_midi : list\n",
    "        List of midi files\n",
    "    batch_music : int\n",
    "      A number of music in one batch\n",
    "    start_index : int\n",
    "      The start index to be batched in list_all_midi\n",
    "    fs : int\n",
    "      Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    use_tqdm : bool\n",
    "      Whether to use tqdm or not in the function\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "    dictionary of music to piano_roll (in np.array)\n",
    "\n",
    "    \"\"\"\n",
    "    assert len(list_all_midi) >= batch_song\n",
    "    \n",
    "    dict_time_notes = {}\n",
    "    process_tqdm_midi = tqdm_notebook(range(start_index, min(start_index + batch_song, len(list_all_midi)))) if use_tqdm else range(start_index,  min(start_index + batch_song, len(list_all_midi)))\n",
    "    for i in process_tqdm_midi:\n",
    "        midi_file_name = list_all_midi[i]\n",
    "        if use_tqdm:\n",
    "            process_tqdm_midi.set_description(\"Processing {}\".format(midi_file_name))\n",
    "        try: # Handle exception on malformat MIDI files\n",
    "            midi_pretty_format = pretty_midi.PrettyMIDI(midi_file_name)\n",
    "            piano_midi = midi_pretty_format.instruments[0] # Get the piano channels\n",
    "            piano_roll = piano_midi.get_piano_roll(fs=fs)\n",
    "            dict_time_notes[i] = piano_roll\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"broken file : {}\".format(midi_file_name))\n",
    "            pass\n",
    "    return dict_time_notes\n",
    "\n",
    "def generate_input_and_target(dict_keys_time, seq_len=50):\n",
    "    \"\"\" Generate input and the target of our deep learning for one music.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    dict_keys_time : dict\n",
    "      Dictionary of timestep and notes\n",
    "    seq_len : int\n",
    "      The length of the sequence\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    Tuple of list of input and list of target of neural network.\n",
    "    \n",
    "       \n",
    "    \"\"\"\n",
    "    # Get the start time and end time\n",
    "    start_time, end_time = list(dict_keys_time.keys())[0], list(dict_keys_time.keys())[-1]\n",
    "    list_training, list_target = [], []\n",
    "    for index_enum, time in enumerate(range(start_time, end_time)):\n",
    "        list_append_training, list_append_target = [], []\n",
    "        start_iterate = 0\n",
    "        flag_target_append = False # flag to append the test list\n",
    "        if index_enum < seq_len:\n",
    "            start_iterate = seq_len - index_enum - 1\n",
    "            for i in range(start_iterate): # add 'e' to the seq list. \n",
    "                list_append_training.append('e')\n",
    "                flag_target_append = True\n",
    "\n",
    "        for i in range(start_iterate,seq_len):\n",
    "            index_enum = time - (seq_len - i - 1)\n",
    "            if index_enum in dict_keys_time:\n",
    "                list_append_training.append(','.join(str(x) for x in dict_keys_time[index_enum]))      \n",
    "            else:\n",
    "                list_append_training.append('e')\n",
    "\n",
    "        # add time + 1 to the list_append_target\n",
    "        if time+1 in dict_keys_time:\n",
    "            list_append_target.append(','.join(str(x) for x in dict_keys_time[time+1]))\n",
    "        else:\n",
    "            list_append_target.append('e')\n",
    "        list_training.append(list_append_training)\n",
    "        list_target.append(list_append_target)\n",
    "    return list_training, list_target\n",
    "\n",
    "def process_notes_in_song(dict_time_notes, seq_len = 50):\n",
    "    \"\"\"\n",
    "    Iterate the dict of piano rolls into dictionary of timesteps and note played\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    dict_time_notes : dict\n",
    "      dict contains index of music ( in index ) to piano_roll (in np.array)\n",
    "    seq_len : int\n",
    "      Length of the sequence\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    Dict of timesteps and note played\n",
    "    \"\"\"\n",
    "    list_of_dict_keys_time = []\n",
    "    \n",
    "    for key in dict_time_notes:\n",
    "        sample = dict_time_notes[key]\n",
    "        times = np.unique(np.where(sample > 0)[1])\n",
    "        index = np.where(sample > 0)\n",
    "        dict_keys_time = {}\n",
    "\n",
    "        for time in times:\n",
    "            index_where = np.where(index[1] == time)\n",
    "            notes = index[0][index_where]\n",
    "            dict_keys_time[time] = notes\n",
    "        list_of_dict_keys_time.append(dict_keys_time)\n",
    "    return list_of_dict_keys_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_200_midi = list_all_midi[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
